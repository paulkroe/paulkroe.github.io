<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on Blog</title>
    <link>http://localhost:1313/posts/</link>
    <description>Recent content in Posts on Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-gb</language>
    <lastBuildDate>Sat, 14 Sep 2024 00:00:00 +0000</lastBuildDate><atom:link href="http://localhost:1313/posts/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Naive Bayes for Text Classification</title>
      <link>http://localhost:1313/posts/naive-bayes/</link>
      <pubDate>Sat, 14 Sep 2024 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/posts/naive-bayes/</guid>
      
      <description>&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;h2 id=&#34;introduction-1&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;Naive Bayes classifiers are simple yet powerful supervised learning algorithms commonly used for text classification tasks such as sentiment analysis, spam detection, language identification, and more. In this blog post, we will explore the theory behind Naive Bayes classifiers and implement one to categorize text in the &lt;a href=&#34;http://qwone.com/~jason/20Newsgroups/&#34;&gt;20 Newsgroups dataset&lt;/a&gt;. When first learning about Naive Bayes, I found the book &lt;a href=&#34;https://web.stanford.edu/~jurafsky/slp3/ed3book.pdf&#34;&gt;&lt;em&gt;Speech and Language Processing&lt;/em&gt;&lt;/a&gt; by Daniel Jurafsky and James H. Martin extremely helpful.&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>LinkedPool</title>
      <link>http://localhost:1313/posts/linkedpool/</link>
      <pubDate>Sun, 01 Sep 2024 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/posts/linkedpool/</guid>
      
      <description>&lt;h2 id=&#34;the-idea&#34;&gt;The Idea&lt;/h2&gt;
&lt;p&gt;Upon starting at Columbia University, introductory lectures often ended with instructors sharing their LinkedIn profiles, inviting students to connect. While connecting with lecturers was great, I found myself more interested in networking with my peers. To address this, I thought of a web application where users could scan a QR code that links to a site displaying the LinkedIn names and profile pictures of others who had scanned the same code. The concept included a feature to connect directly via a simple button next to each name.
From the start, I knew the application needed to be as seamless as possible to have any chance of being used. With this intuition in mind, I coined the name LinkedPool, sought a logo from DALL-E, and began the development process.&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>Schokoban: Using Monte Carlo Tree Search for Solving Sokoban</title>
      <link>http://localhost:1313/posts/schokoban/</link>
      <pubDate>Thu, 18 Jul 2024 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/posts/schokoban/</guid>
      
      <description>&lt;p&gt;&lt;img alt=&#34;Sokoban Puzzle&#34; src=&#34;http://localhost:1313/level_1.png&#34; title=&#34;Sokoban Puzzle&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Level 1 from the original Sokoban game&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;In my Bachelor&amp;rsquo;s thesis, under the supervision of &lt;a href=&#34;https://people.math.ethz.ch/~jopeters/&#34;&gt;Professor Dr. Peters&lt;/a&gt;, I explored the application of Monte Carlo Tree Search to the puzzle game Sokoban. Sokoban challenges players to push boxes onto designated targets within a warehouse. Even though the rules of Sokoban are simple, they still allow for complex and engaging puzzles. The research presents a novel approach to manage redundant state representations within the Monte Carlo Search Tree, significantly enhancing the algorithmâ€™s ability to solve problems. Below is a preview of the comparative results between the baseline and the improved algorithm.&lt;/p&gt;</description>
      
    </item>
    
  </channel>
</rss>
